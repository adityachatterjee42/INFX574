{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PART 1\n",
    "#1 --> solution in pdf of images, attached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x->1\n",
      "f(x)->-1\n",
      "gradient->-2\n",
      "recomputed x->0.8\n",
      "x->0.8\n",
      "f(x)->-0.6400000000000001\n",
      "gradient->-1.6\n",
      "recomputed x->0.64\n",
      "x->0.64\n",
      "f(x)->-0.4096\n",
      "gradient->-1.28\n",
      "recomputed x->0.512\n",
      "x->0.512\n",
      "f(x)->-0.262144\n",
      "gradient->-1.024\n",
      "recomputed x->0.4096\n",
      "x->0.4096\n",
      "f(x)->-0.16777216\n",
      "gradient->-0.8192\n",
      "recomputed x->0.32768\n",
      "x->0.32768\n",
      "f(x)->-0.10737418240000002\n",
      "gradient->-0.65536\n",
      "recomputed x->0.26214400000000004\n",
      "x->0.26214400000000004\n",
      "f(x)->-0.06871947673600003\n",
      "gradient->-0.5242880000000001\n",
      "recomputed x->0.20971520000000005\n",
      "x->0.20971520000000005\n",
      "f(x)->-0.04398046511104002\n",
      "gradient->-0.4194304000000001\n",
      "recomputed x->0.16777216000000003\n",
      "x->0.16777216000000003\n",
      "f(x)->-0.02814749767106561\n",
      "gradient->-0.33554432000000006\n",
      "recomputed x->0.13421772800000004\n",
      "x->0.13421772800000004\n",
      "f(x)->-0.018014398509481992\n",
      "gradient->-0.26843545600000007\n",
      "recomputed x->0.10737418240000003\n",
      "x->0.10737418240000003\n",
      "f(x)->-0.011529215046068476\n",
      "gradient->-0.21474836480000006\n",
      "recomputed x->0.08589934592000002\n",
      "x->0.08589934592000002\n",
      "f(x)->-0.0073786976294838245\n",
      "gradient->-0.17179869184000005\n",
      "recomputed x->0.06871947673600001\n",
      "x->0.06871947673600001\n",
      "f(x)->-0.004722366482869647\n",
      "gradient->-0.13743895347200002\n",
      "recomputed x->0.05497558138880001\n",
      "x->0.05497558138880001\n",
      "f(x)->-0.003022314549036574\n",
      "gradient->-0.10995116277760002\n",
      "recomputed x->0.04398046511104001\n",
      "x->0.04398046511104001\n",
      "f(x)->-0.0019342813113834073\n",
      "gradient->-0.08796093022208001\n",
      "recomputed x->0.035184372088832\n",
      "x->0.035184372088832\n",
      "f(x)->-0.0012379400392853804\n",
      "gradient->-0.070368744177664\n",
      "recomputed x->0.028147497671065603\n",
      "x->0.028147497671065603\n",
      "f(x)->-0.0007922816251426435\n",
      "gradient->-0.056294995342131206\n",
      "recomputed x->0.02251799813685248\n",
      "maxima reached in 17 iterations!\n",
      "--------------------------------------------------\n",
      "x->2\n",
      "f(x)->-4\n",
      "gradient->-4\n",
      "recomputed x->1.2\n",
      "x->1.2\n",
      "f(x)->-1.44\n",
      "gradient->-2.4\n",
      "recomputed x->0.72\n",
      "x->0.72\n",
      "f(x)->-0.5184\n",
      "gradient->-1.44\n",
      "recomputed x->0.432\n",
      "x->0.432\n",
      "f(x)->-0.18662399999999998\n",
      "gradient->-0.864\n",
      "recomputed x->0.2592\n",
      "x->0.2592\n",
      "f(x)->-0.06718463999999999\n",
      "gradient->-0.5184\n",
      "recomputed x->0.15552\n",
      "x->0.15552\n",
      "f(x)->-0.024186470399999997\n",
      "gradient->-0.31104\n",
      "recomputed x->0.09331199999999999\n",
      "x->0.09331199999999999\n",
      "f(x)->-0.008707129343999998\n",
      "gradient->-0.18662399999999998\n",
      "recomputed x->0.055987199999999994\n",
      "x->0.055987199999999994\n",
      "f(x)->-0.0031345665638399995\n",
      "gradient->-0.11197439999999999\n",
      "recomputed x->0.033592319999999995\n",
      "x->0.033592319999999995\n",
      "f(x)->-0.0011284439629823996\n",
      "gradient->-0.06718463999999999\n",
      "recomputed x->0.020155391999999994\n",
      "x->0.020155391999999994\n",
      "f(x)->-0.0004062398266736638\n",
      "gradient->-0.04031078399999999\n",
      "recomputed x->0.012093235199999997\n",
      "x->0.012093235199999997\n",
      "f(x)->-0.00014624633760251896\n",
      "gradient->-0.024186470399999993\n",
      "recomputed x->0.007255941119999998\n",
      "x->0.007255941119999998\n",
      "f(x)->-5.264868153690683e-05\n",
      "gradient->-0.014511882239999996\n",
      "recomputed x->0.004353564671999998\n",
      "x->0.004353564671999998\n",
      "f(x)->-1.895352535328645e-05\n",
      "gradient->-0.008707129343999996\n",
      "recomputed x->0.0026121388031999987\n",
      "x->0.0026121388031999987\n",
      "f(x)->-6.823269127183122e-06\n",
      "gradient->-0.005224277606399997\n",
      "recomputed x->0.0015672832819199991\n",
      "maxima reached in 14 iterations!\n",
      "--------------------------------------------------\n",
      "x->1\n",
      "f(x)->-1\n",
      "gradient->-2\n",
      "recomputed x->0.8\n",
      "x->0.8\n",
      "f(x)->-0.6400000000000001\n",
      "gradient->-1.6\n",
      "recomputed x->0.64\n",
      "x->0.64\n",
      "f(x)->-0.4096\n",
      "gradient->-1.28\n",
      "recomputed x->0.512\n",
      "x->0.512\n",
      "f(x)->-0.262144\n",
      "gradient->-1.024\n",
      "recomputed x->0.4096\n",
      "x->0.4096\n",
      "f(x)->-0.16777216\n",
      "gradient->-0.8192\n",
      "recomputed x->0.32768\n",
      "x->0.32768\n",
      "f(x)->-0.10737418240000002\n",
      "gradient->-0.65536\n",
      "recomputed x->0.26214400000000004\n",
      "x->0.26214400000000004\n",
      "f(x)->-0.06871947673600003\n",
      "gradient->-0.5242880000000001\n",
      "recomputed x->0.20971520000000005\n",
      "x->0.20971520000000005\n",
      "f(x)->-0.04398046511104002\n",
      "gradient->-0.4194304000000001\n",
      "recomputed x->0.16777216000000003\n",
      "x->0.16777216000000003\n",
      "f(x)->-0.02814749767106561\n",
      "gradient->-0.33554432000000006\n",
      "recomputed x->0.13421772800000004\n",
      "x->0.13421772800000004\n",
      "f(x)->-0.018014398509481992\n",
      "gradient->-0.26843545600000007\n",
      "recomputed x->0.10737418240000003\n",
      "x->0.10737418240000003\n",
      "f(x)->-0.011529215046068476\n",
      "gradient->-0.21474836480000006\n",
      "recomputed x->0.08589934592000002\n",
      "x->0.08589934592000002\n",
      "f(x)->-0.0073786976294838245\n",
      "gradient->-0.17179869184000005\n",
      "recomputed x->0.06871947673600001\n",
      "x->0.06871947673600001\n",
      "f(x)->-0.004722366482869647\n",
      "gradient->-0.13743895347200002\n",
      "recomputed x->0.05497558138880001\n",
      "x->0.05497558138880001\n",
      "f(x)->-0.003022314549036574\n",
      "gradient->-0.10995116277760002\n",
      "recomputed x->0.04398046511104001\n",
      "x->0.04398046511104001\n",
      "f(x)->-0.0019342813113834073\n",
      "gradient->-0.08796093022208001\n",
      "recomputed x->0.035184372088832\n",
      "x->0.035184372088832\n",
      "f(x)->-0.0012379400392853804\n",
      "gradient->-0.070368744177664\n",
      "recomputed x->0.028147497671065603\n",
      "x->0.028147497671065603\n",
      "f(x)->-0.0007922816251426435\n",
      "gradient->-0.056294995342131206\n",
      "recomputed x->0.02251799813685248\n",
      "x->0.02251799813685248\n",
      "f(x)->-0.0005070602400912918\n",
      "gradient->-0.04503599627370496\n",
      "recomputed x->0.018014398509481985\n",
      "x->0.018014398509481985\n",
      "f(x)->-0.00032451855365842676\n",
      "gradient->-0.03602879701896397\n",
      "recomputed x->0.014411518807585589\n",
      "x->0.014411518807585589\n",
      "f(x)->-0.00020769187434139315\n",
      "gradient->-0.028823037615171177\n",
      "recomputed x->0.01152921504606847\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "2 and 3\n",
    "'''\n",
    "\n",
    "#defining function from assignment as well as the 1D gradient defined as partial derivative\n",
    "def f(x):\n",
    "    return -(x*x)\n",
    "\n",
    "def gradient(x):\n",
    "    return -(2*x)\n",
    "\n",
    "#iterative gradient ascent function\n",
    "def gradientAscent(x0, r, iterations, e):\n",
    "    x=x0\n",
    "    iterCount=1\n",
    "    while(iterCount<=iterations):\n",
    "        print(\"x->{0}\".format(x))\n",
    "        print(\"f(x)->{0}\".format(f(x)))\n",
    "        print(\"gradient->{0}\".format(gradient(x)))\n",
    "        x = x + r * gradient(x)\n",
    "        print(\"recomputed x->{0}\".format(x))\n",
    "        if(abs(gradient(x))<e):\n",
    "            print(\"maxima reached in {0} iterations!\".format(iterCount))\n",
    "            break\n",
    "        iterCount+=1\n",
    "\n",
    "#running gradient ascent functions with various starting paramters\n",
    "gradientAscent(x0=1, r=0.1, iterations=20, e=0.05)\n",
    "print(\"--------------------------------------------------\")\n",
    "gradientAscent(x0=2, r=0.2, iterations=20, e=0.005)\n",
    "print(\"--------------------------------------------------\")\n",
    "gradientAscent(x0=1, r=0.1, iterations=20, e=0.0005)\n",
    "print(\"--------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4,5,6 --> solution in pdf of images, attached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x->[ 2 -3]\n",
      "f(x)->-52\n",
      "gradient->[ 8 40]\n",
      "recomputed x->[ 2.8  1. ]\n",
      "x->[ 2.8  1. ]\n",
      "f(x)->-27.04\n",
      "gradient->[ -9.6 -27.2]\n",
      "recomputed x->[ 1.84 -1.72]\n",
      "x->[ 1.84 -1.72]\n",
      "f(x)->-14.393600000000005\n",
      "gradient->[  3.2   20.16]\n",
      "recomputed x->[ 2.16   0.296]\n",
      "x->[ 2.16   0.296]\n",
      "f(x)->-7.923968000000005\n",
      "gradient->[ -5.504 -13.376]\n",
      "recomputed x->[ 1.6096 -1.0416]\n",
      "x->[ 1.6096 -1.0416]\n",
      "f(x)->-4.564019200000003\n",
      "gradient->[  0.9472  10.2272]\n",
      "recomputed x->[ 1.70432 -0.01888]\n",
      "x->[ 1.70432 -0.01888]\n",
      "f(x)->-2.7788480512000016\n",
      "gradient->[-3.33312 -6.5152 ]\n",
      "recomputed x->[ 1.371008 -0.6704  ]\n",
      "x->[ 1.371008 -0.6704  ]\n",
      "f(x)->-1.7986571632640012\n",
      "gradient->[-0.060416  5.242368]\n",
      "recomputed x->[ 1.3649664 -0.1461632]\n",
      "x->[ 1.3649664 -0.1461632]\n",
      "f(x)->-1.2360112937369607\n",
      "gradient->[-2.14528   -3.1212544]\n",
      "recomputed x->[ 1.1504384  -0.45828864]\n",
      "x->[ 1.1504384  -0.45828864]\n",
      "f(x)->-0.8948049336598534\n",
      "gradient->[-0.46772224  2.73086464]\n",
      "recomputed x->[ 1.10366618 -0.18520218]\n",
      "x->[ 1.10366618 -0.18520218]\n",
      "f(x)->-0.6748722865163473\n",
      "gradient->[-1.46652365 -1.45142989]\n",
      "recomputed x->[ 0.95701381 -0.33034516]\n",
      "x->[ 0.95701381 -0.33034516]\n",
      "f(x)->-0.5243193173745024\n",
      "gradient->[-0.59264696  1.45746739]\n",
      "recomputed x->[ 0.89774911 -0.18459843]\n",
      "x->[ 0.89774911 -0.18459843]\n",
      "f(x)->-0.41567381037724727\n",
      "gradient->[-1.05710453 -0.63742165]\n",
      "recomputed x->[ 0.79203866 -0.24834059]\n",
      "x->[ 0.79203866 -0.24834059]\n",
      "f(x)->-0.33392823730137033\n",
      "gradient->[-0.59071496  0.8052948 ]\n",
      "recomputed x->[ 0.73296717 -0.16781111]\n",
      "x->[ 0.73296717 -0.16781111]\n",
      "f(x)->-0.27052528050728825\n",
      "gradient->[-0.79468989 -0.2468909 ]\n",
      "recomputed x->[ 0.65349818 -0.1925002 ]\n",
      "x->[ 0.65349818 -0.1925002 ]\n",
      "f(x)->-0.22031636427097925\n",
      "gradient->[-0.53699555  0.46601049]\n",
      "recomputed x->[ 0.59979862 -0.14589915]\n",
      "x->[ 0.59979862 -0.14589915]\n",
      "f(x)->-0.18001044594190735\n",
      "gradient->[-0.61600064 -0.06480807]\n",
      "recomputed x->[ 0.53819856 -0.15237996]\n",
      "x->[ 0.53819856 -0.15237996]\n",
      "f(x)->-0.14737220583792462\n",
      "gradient->[-0.46687728  0.2852851 ]\n",
      "recomputed x->[ 0.49151083 -0.12385145]\n",
      "x->[ 0.49151083 -0.12385145]\n",
      "f(x)->-0.12079903304825522\n",
      "gradient->[-0.48761587  0.01557985]\n",
      "recomputed x->[ 0.44274924 -0.12229346]\n",
      "x->[ 0.44274924 -0.12229346]\n",
      "f(x)->-0.099091068112483\n",
      "gradient->[-0.39632463  0.18569844]\n",
      "recomputed x->[ 0.40311678 -0.10372362]\n",
      "x->[ 0.40311678 -0.10372362]\n",
      "f(x)->-0.08132092597191219\n",
      "gradient->[-0.39133908  0.04711079]\n",
      "recomputed x->[ 0.36398287 -0.09901254]\n",
      "x->[ 0.36398287 -0.09901254]\n",
      "f(x)->-0.06675592078405106\n",
      "gradient->[-0.33191558  0.12826916]\n",
      "recomputed x->[ 0.33079131 -0.08618562]\n",
      "x->[ 0.33079131 -0.08618562]\n",
      "f(x)->-0.05480876415685216\n",
      "gradient->[-0.31684013  0.05580474]\n",
      "recomputed x->[ 0.2991073  -0.08060515]\n",
      "x->[ 0.2991073  -0.08060515]\n",
      "f(x)->-0.045004343533897546\n",
      "gradient->[-0.275794    0.09325321]\n",
      "recomputed x->[ 0.2715279  -0.07127983]\n",
      "x->[ 0.2715279  -0.07127983]\n",
      "f(x)->-0.03695606366609811\n",
      "gradient->[-0.25793648  0.05436567]\n",
      "recomputed x->[ 0.24573425 -0.06584326]\n",
      "x->[ 0.24573425 -0.06584326]\n",
      "f(x)->-0.030348224927765073\n",
      "gradient->[-0.22809546  0.07055519]\n",
      "recomputed x->[ 0.22292471 -0.05878774]\n",
      "x->[ 0.22292471 -0.05878774]\n",
      "f(x)->-0.024922453227016108\n",
      "gradient->[-0.21069844  0.04890507]\n",
      "recomputed x->[ 0.20185486 -0.05389724]\n",
      "x->[ 0.20185486 -0.05389724]\n",
      "f(x)->-0.02046700532924869\n",
      "gradient->[-0.18812078  0.05493633]\n",
      "recomputed x->[ 0.18304278 -0.0484036 ]\n",
      "x->[ 0.18304278 -0.0484036 ]\n",
      "f(x)->-0.01680821019282247\n",
      "gradient->[-0.17247116  0.04228651]\n",
      "recomputed x->[ 0.16579567 -0.04417495]\n",
      "x->[ 0.16579567 -0.04417495]\n",
      "f(x)->-0.0138035520716654\n",
      "gradient->[-0.15489153  0.04361656]\n",
      "recomputed x->[ 0.15030652 -0.0398133 ]\n",
      "x->[ 0.15030652 -0.0398133 ]\n",
      "f(x)->-0.011336045839618244\n",
      "gradient->[-0.14135985  0.03578668]\n",
      "recomputed x->[ 0.13617053 -0.03623463]\n",
      "x->[ 0.13617053 -0.03623463]\n",
      "f(x)->-0.009309645579741933\n",
      "gradient->[-0.12740255  0.03507193]\n",
      "recomputed x->[ 0.12343028 -0.03272744]\n",
      "x->[ 0.12343028 -0.03272744]\n",
      "f(x)->-0.00764548778935172\n",
      "gradient->[-0.11595081  0.02991786]\n",
      "recomputed x->[ 0.1118352  -0.02973565]\n",
      "x->[ 0.1118352  -0.02973565]\n",
      "f(x)->-0.006278813052481974\n",
      "gradient->[-0.10472779  0.02842961]\n",
      "recomputed x->[ 0.10136242 -0.02689269]\n",
      "x->[ 0.10136242 -0.02689269]\n",
      "f(x)->-0.005156441430757741\n",
      "gradient->[-0.09515408  0.02483335]\n",
      "recomputed x->[ 0.09184701 -0.02440935]\n",
      "x->[ 0.09184701 -0.02440935]\n",
      "f(x)->-0.004234700862303601\n",
      "gradient->[-0.0860566   0.02316162]\n",
      "recomputed x->[ 0.08324135 -0.02209319]\n",
      "x->[ 0.08324135 -0.02209319]\n",
      "f(x)->-0.003477726728202384\n",
      "gradient->[-0.07810993  0.02052567]\n",
      "recomputed x->[ 0.07543035 -0.02004062]\n",
      "x->[ 0.07543035 -0.02004062]\n",
      "f(x)->-0.002856065808027591\n",
      "gradient->[-0.07069821  0.01892857]\n",
      "recomputed x->[ 0.06836053 -0.01814777]\n",
      "x->[ 0.06836053 -0.01814777]\n",
      "f(x)->-0.0023455299987247234\n",
      "gradient->[-0.06413     0.01692214]\n",
      "recomputed x->[ 0.06194753 -0.01645555]\n",
      "x->[ 0.06194753 -0.01645555]\n",
      "f(x)->-0.0019262550433485342\n",
      "gradient->[-0.05807286  0.01549871]\n",
      "recomputed x->[ 0.05614025 -0.01490568]\n",
      "x->[ 0.05614025 -0.01490568]\n",
      "f(x)->-0.001581927569742418\n",
      "gradient->[-0.05265777  0.01392991]\n",
      "recomputed x->[ 0.05087447 -0.01351269]\n",
      "x->[ 0.05087447 -0.01351269]\n",
      "f(x)->-0.0012991503263044325\n",
      "gradient->[-0.04769818  0.01270516]\n",
      "recomputed x->[ 0.04610465 -0.01224217]\n",
      "x->[ 0.04610465 -0.01224217]\n",
      "f(x)->-0.0010669208981553564\n",
      "gradient->[-0.04324061  0.01145618]\n",
      "recomputed x->[ 0.04178059 -0.01109656]\n",
      "x->[ 0.04178059 -0.01109656]\n",
      "f(x)->-0.0008762036119107747\n",
      "gradient->[-0.03917496  0.01042254]\n",
      "recomputed x->[ 0.0378631 -0.0100543]\n",
      "x->[ 0.0378631 -0.0100543]\n",
      "f(x)->-0.0007195779678377888\n",
      "gradient->[-0.03550898  0.00941646]\n",
      "recomputed x->[ 0.0343122  -0.00911266]\n",
      "x->[ 0.0343122  -0.00911266]\n",
      "f(x)->-0.0005909499181072278\n",
      "gradient->[-0.03217377  0.00855372]\n",
      "recomputed x->[ 0.03109482 -0.00825729]\n",
      "x->[ 0.03109482 -0.00825729]\n",
      "f(x)->-0.0004853147562751825\n",
      "gradient->[-0.0291605   0.00773728]\n",
      "recomputed x->[ 0.02817877 -0.00748356]\n",
      "x->[ 0.02817877 -0.00748356]\n",
      "f(x)->-0.00039856239182652027\n",
      "gradient->[-0.02642331  0.00702183]\n",
      "recomputed x->[ 0.02553644 -0.00678137]\n",
      "x->[ 0.02553644 -0.00678137]\n",
      "f(x)->-0.00032731743304069205\n",
      "gradient->[-0.02394738  0.00635622]\n",
      "recomputed x->[ 0.0231417  -0.00614575]\n",
      "x->[ 0.0231417  -0.00614575]\n",
      "f(x)->-0.00026880785592157074\n",
      "gradient->[-0.0217004   0.00576522]\n",
      "recomputed x->[ 0.02097166 -0.00556923]\n",
      "x->[ 0.02097166 -0.00556923]\n",
      "f(x)->-0.00022075714924300592\n",
      "gradient->[-0.01966641  0.00522103]\n",
      "recomputed x->[ 0.01900502 -0.00504713]\n"
     ]
    }
   ],
   "source": [
    "#7,8\n",
    "#2D case\n",
    "x0 = np.array([2,-3])\n",
    "a = np.array([[1,2],[2,8]])\n",
    "\n",
    "\n",
    "def f(a,x):\n",
    "    return -1*np.matmul(np.transpose(x),np.matmul(a,x))\n",
    "\n",
    "def gradient(a,x):\n",
    "    return -2*(np.matmul(a,x))\n",
    "\n",
    "#iterative gradient ascent function\n",
    "def gradientAscent2D(x0, r, iterations, e):\n",
    "    x=x0\n",
    "    iterCount=1\n",
    "    while(iterCount<=iterations):\n",
    "        print(\"x->{0}\".format(x))\n",
    "        print(\"f(x)->{0}\".format(f(a,x)))\n",
    "        print(\"gradient->{0}\".format(gradient(a,x)))\n",
    "        x = x + r * gradient(a,x)\n",
    "        print(\"recomputed x->{0}\".format(x))\n",
    "        '''\n",
    "        if(abs(gradient(a,x))<e):\n",
    "            print(\"maxima reached in {0} iterations!\".format(iterCount))\n",
    "            break\n",
    "        '''\n",
    "        iterCount+=1\n",
    "\n",
    "#print(f(a,x0))\n",
    "#print(gradient(a,x0))\n",
    "\n",
    "gradientAscent2D(x0, 0.1, 50, 0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x->[10 20 30 40 50]\n",
      "f(x)->-427500\n",
      "gradient->[-2900 -4000 -6100 -6200 -6300]\n",
      "recomputed x->[-280. -380. -580. -580. -580.]\n",
      "x->[-280. -380. -580. -580. -580.]\n",
      "f(x)->-98720000.0\n",
      "gradient->[ 44000.  60400.  90400.  93200.  96000.]\n",
      "recomputed x->[ 4120.  5660.  8460.  8740.  9020.]\n",
      "x->[ 4120.  5660.  8460.  8740.  9020.]\n",
      "f(x)->-22362864000.0\n",
      "gradient->[ -663680.  -910480. -1362880. -1404080. -1445280.]\n",
      "recomputed x->[ -62248.  -85388. -127828. -131668. -135508.]\n",
      "x->[ -62248.  -85388. -127828. -131668. -135508.]\n",
      "f(x)->-5077323161600.0\n",
      "gradient->[  9998720.  13717360.  20532160.  21154640.  21777120.]\n",
      "recomputed x->[  937624.  1286348.  1925388.  1983796.  2042204.]\n",
      "x->[  937624.  1286348.  1925388.  1983796.  2042204.]\n",
      "f(x)->-1152534350736000.0\n",
      "gradient->[ -1.50647168e+08  -2.06673808e+08  -3.09350848e+08  -3.18727088e+08\n",
      "  -3.28103328e+08]\n",
      "recomputed x->[-14127092.8 -19381032.8 -29009696.8 -29888912.8 -30768128.8]\n",
      "x->[-14127092.8 -19381032.8 -29009696.8 -29888912.8 -30768128.8]\n",
      "f(x)->-2.616263697490373e+17\n",
      "gradient->[  2.26972966e+09   3.11385765e+09   4.66084269e+09   4.80211362e+09\n",
      "   4.94338454e+09]\n",
      "recomputed x->[  2.12845874e+08   2.92004732e+08   4.37074572e+08   4.50322449e+08\n",
      "   4.63570326e+08]\n",
      "x->[  2.12845874e+08   2.92004732e+08   4.37074572e+08   4.50322449e+08\n",
      "   4.63570326e+08]\n",
      "f(x)->-5.938931816116399e+19\n",
      "gradient->[ -3.41969685e+10  -4.69150534e+10  -7.02227644e+10  -7.23512232e+10\n",
      "  -7.44796819e+10]\n",
      "recomputed x->[ -3.20685098e+09  -4.39950061e+09  -6.58520187e+09  -6.78479987e+09\n",
      "  -6.98439786e+09]\n",
      "x->[ -3.20685098e+09  -4.39950061e+09  -6.58520187e+09  -6.78479987e+09\n",
      "  -6.98439786e+09]\n",
      "f(x)->-1.3481407646391876e+22\n",
      "gradient->[  5.15229894e+11   7.06847394e+11   1.05801388e+12   1.09008239e+12\n",
      "   1.12215090e+12]\n",
      "recomputed x->[  4.83161385e+10   6.62852388e+10   9.92161865e+10   1.02223439e+11\n",
      "   1.05230692e+11]\n",
      "x->[  4.83161385e+10   6.62852388e+10   9.92161865e+10   1.02223439e+11\n",
      "   1.05230692e+11]\n",
      "f(x)->-3.060286843862797e+24\n",
      "gradient->[ -7.76273036e+12  -1.06497425e+13  -1.59406055e+13  -1.64237669e+13\n",
      "  -1.69069283e+13]\n",
      "recomputed x->[ -7.27956898e+11  -9.98689016e+11  -1.49484437e+12  -1.54015325e+12\n",
      "  -1.58546214e+12]\n",
      "x->[ -7.27956898e+11  -9.98689016e+11  -1.49484437e+12  -1.54015325e+12\n",
      "  -1.58546214e+12]\n",
      "f(x)->-6.946867736340198e+26\n",
      "gradient->[  1.16957466e+14   1.60454742e+14   2.40169726e+14   2.47449295e+14\n",
      "   2.54728864e+14]\n",
      "recomputed x->[  1.09677897e+13   1.50467852e+13   2.25221282e+13   2.32047762e+13\n",
      "   2.38874242e+13]\n",
      "x->[  1.09677897e+13   1.50467852e+13   2.25221282e+13   2.32047762e+13\n",
      "   2.38874242e+13]\n",
      "f(x)->-1.576942744289466e+29\n",
      "gradient->[ -1.76214400e+15  -2.41749733e+15  -3.61852610e+15  -3.72820400e+15\n",
      "  -3.83788189e+15]\n",
      "recomputed x->[ -1.65246611e+14  -2.26702948e+14  -3.39330482e+14  -3.49615623e+14\n",
      "  -3.59900765e+14]\n",
      "x->[ -1.65246611e+14  -2.26702948e+14  -3.39330482e+14  -3.49615623e+14\n",
      "  -3.59900765e+14]\n",
      "f(x)->-3.57966858328866e+31\n",
      "gradient->[  2.65494081e+16   3.64233135e+16   5.45186580e+16   5.61711241e+16\n",
      "   5.78235902e+16]\n",
      "recomputed x->[  2.48969420e+15   3.41562840e+15   5.11253532e+15   5.26749679e+15\n",
      "   5.42245826e+15]\n",
      "x->[  2.48969420e+15   3.41562840e+15   5.11253532e+15   5.26749679e+15\n",
      "   5.42245826e+15]\n",
      "f(x)->-8.125867101116302e+33\n",
      "gradient->[ -4.00007644e+17  -5.48773206e+17  -8.21407387e+17  -8.46304329e+17\n",
      "  -8.71201271e+17]\n",
      "recomputed x->[ -3.75110702e+16  -5.14616922e+16  -7.70282034e+16  -7.93629362e+16\n",
      "  -8.16976689e+16]\n",
      "x->[ -3.75110702e+16  -5.14616922e+16  -7.70282034e+16  -7.93629362e+16\n",
      "  -8.16976689e+16]\n",
      "f(x)->-1.8445762396347667e+36\n",
      "gradient->[  6.02673005e+18   8.26811191e+18   1.23757649e+19   1.27508756e+19\n",
      "   1.31259863e+19]\n",
      "recomputed x->[  5.65161934e+17   7.75349499e+17   1.16054829e+18   1.19572463e+18\n",
      "   1.23090097e+18]\n",
      "x->[  5.65161934e+17   7.75349499e+17   1.16054829e+18   1.19572463e+18\n",
      "   1.23090097e+18]\n",
      "f(x)->-4.187198069431478e+38\n",
      "gradient->[ -9.08019523e+19  -1.24571815e+20  -1.86459923e+20  -1.92111542e+20\n",
      "  -1.97763161e+20]\n",
      "recomputed x->[ -8.51503329e+18  -1.16818320e+19  -1.74854440e+19  -1.80154296e+19\n",
      "  -1.85454152e+19]\n",
      "x->[ -8.51503329e+18  -1.16818320e+19  -1.74854440e+19  -1.80154296e+19\n",
      "  -1.85454152e+19]\n",
      "f(x)->-9.504962330059202e+40\n",
      "gradient->[  1.36807099e+21   1.87686589e+21   2.80930535e+21   2.89445569e+21\n",
      "   2.97960602e+21]\n",
      "recomputed x->[  1.28292066e+20   1.76004757e+20   2.63445091e+20   2.71430139e+20\n",
      "   2.79415187e+20]\n",
      "x->[  1.28292066e+20   1.76004757e+20   2.63445091e+20   2.71430139e+20\n",
      "   2.79415187e+20]\n",
      "f(x)->-2.1576316046618508e+43\n",
      "gradient->[ -2.06120924e+22  -2.82778697e+22  -4.23265035e+22  -4.36094242e+22\n",
      "  -4.48923449e+22]\n",
      "recomputed x->[ -1.93291718e+21  -2.65178221e+21  -3.96920526e+21  -4.08951228e+21\n",
      "  -4.20981930e+21]\n",
      "x->[ -1.93291718e+21  -2.65178221e+21  -3.96920526e+21  -4.08951228e+21\n",
      "  -4.20981930e+21]\n",
      "f(x)->-4.897835446136563e+45\n",
      "gradient->[  3.10552857e+23   4.26049575e+23   6.37713839e+23   6.57043011e+23\n",
      "   6.76372183e+23]\n",
      "recomputed x->[  2.91223685e+22   3.99531753e+22   5.98021787e+22   6.16147888e+22\n",
      "   6.34273990e+22]\n",
      "x->[  2.91223685e+22   3.99531753e+22   5.98021787e+22   6.16147888e+22\n",
      "   6.34273990e+22]\n",
      "f(x)->-1.1118113029861426e+48\n",
      "gradient->[ -4.67895616e+24  -6.41909176e+24  -9.60813926e+24  -9.89936295e+24\n",
      "  -1.01905866e+25]\n",
      "recomputed x->[ -4.38773247e+23  -6.01956000e+23  -9.01011748e+23  -9.28321506e+23\n",
      "  -9.55631264e+23]\n",
      "x->[ -4.38773247e+23  -6.01956000e+23  -9.01011748e+23  -9.28321506e+23\n",
      "  -9.55631264e+23]\n",
      "f(x)->-2.523817688531789e+50\n",
      "gradient->[  7.04956669e+25   9.67134846e+25   1.44761387e+26   1.49149120e+26\n",
      "   1.53536852e+26]\n",
      "recomputed x->[  6.61079344e+24   9.06939246e+24   1.35751270e+25   1.39865905e+25\n",
      "   1.43980540e+25]\n",
      "x->[  6.61079344e+24   9.06939246e+24   1.35751270e+25   1.39865905e+25\n",
      "   1.43980540e+25]\n",
      "f(x)->-5.729079842809741e+52\n",
      "gradient->[ -1.06212559e+27  -1.45713731e+27  -2.18105282e+27  -2.24716076e+27\n",
      "  -2.31326869e+27]\n",
      "recomputed x->[ -9.96017652e+25  -1.36644339e+26  -2.04530155e+26  -2.10729485e+26\n",
      "  -2.16928815e+26]\n",
      "x->[ -9.96017652e+25  -1.36644339e+26  -2.04530155e+26  -2.10729485e+26\n",
      "  -2.16928815e+26]\n",
      "f(x)->-1.3005042319195027e+55\n",
      "gradient->[  1.60025546e+28   2.19540135e+28   3.28609135e+28   3.38569311e+28\n",
      "   3.48529488e+28]\n",
      "recomputed x->[  1.50065370e+27   2.05875701e+27   3.08156119e+27   3.17496363e+27\n",
      "   3.26836606e+27]\n",
      "x->[  1.50065370e+27   2.05875701e+27   3.08156119e+27   3.17496363e+27\n",
      "   3.26836606e+27]\n",
      "f(x)->-2.9521516607299664e+57\n",
      "gradient->[ -2.41103084e+29  -3.30770960e+29  -4.95100174e+29  -5.10106711e+29\n",
      "  -5.25113248e+29]\n",
      "recomputed x->[ -2.26096547e+28  -3.10183390e+28  -4.64284562e+28  -4.78357075e+28\n",
      "  -4.92429588e+28]\n",
      "x->[ -2.26096547e+28  -3.10183390e+28  -4.64284562e+28  -4.78357075e+28\n",
      "  -4.92429588e+28]\n",
      "f(x)->-6.701400283094309e+59\n",
      "gradient->[  3.63258858e+30   4.98357296e+30   7.45944518e+30   7.68554173e+30\n",
      "   7.91163828e+30]\n",
      "recomputed x->[  3.40649203e+29   4.67338957e+29   6.99516062e+29   7.20718465e+29\n",
      "   7.41920869e+29]\n",
      "x->[  3.40649203e+29   4.67338957e+29   6.99516062e+29   7.20718465e+29\n",
      "   7.41920869e+29]\n",
      "f(x)->-1.5212214992759575e+62\n",
      "gradient->[ -5.47305309e+31  -7.50851873e+31  -1.12388008e+32  -1.15794500e+32\n",
      "  -1.19200992e+32]\n",
      "recomputed x->[ -5.13240389e+30  -7.04117977e+30  -1.05392847e+31  -1.08587315e+31\n",
      "  -1.11781783e+31]\n",
      "x->[ -5.13240389e+30  -7.04117977e+30  -1.05392847e+31  -1.08587315e+31\n",
      "  -1.11781783e+31]\n",
      "f(x)->-3.4531810548568974e+64\n",
      "gradient->[  8.24599578e+32   1.13127377e+33   1.69329810e+33   1.74462214e+33\n",
      "   1.79594618e+33]\n",
      "recomputed x->[  7.73275539e+31   1.06086197e+32   1.58790525e+32   1.63603483e+32\n",
      "   1.68416440e+32]\n",
      "x->[  7.73275539e+31   1.06086197e+32   1.58790525e+32   1.63603483e+32\n",
      "   1.68416440e+32]\n",
      "f(x)->-7.838739725475993e+66\n",
      "gradient->[ -1.24238602e+34  -1.70443782e+34  -2.55121388e+34  -2.62854143e+34\n",
      "  -2.70586899e+34]\n",
      "recomputed x->[ -1.16505847e+33  -1.59835163e+33  -2.39242336e+33  -2.46493795e+33\n",
      "  -2.53745255e+33]\n",
      "x->[ -1.16505847e+33  -1.59835163e+33  -2.39242336e+33  -2.46493795e+33\n",
      "  -2.53745255e+33]\n",
      "f(x)->-1.7793981696190503e+69\n",
      "gradient->[  1.87184552e+35   2.56799758e+35   3.84379588e+35   3.96030172e+35\n",
      "   4.07680757e+35]\n",
      "recomputed x->[  1.75533967e+34   2.40816242e+34   3.60455354e+34   3.71380793e+34\n",
      "   3.82306232e+34]\n",
      "x->[  1.75533967e+34   2.40816242e+34   3.60455354e+34   3.71380793e+34\n",
      "   3.82306232e+34]\n",
      "f(x)->-4.0392434969530264e+71\n",
      "gradient->[ -2.82022300e+36  -3.86908311e+36  -5.79126935e+36  -5.96680331e+36\n",
      "  -6.14233728e+36]\n",
      "recomputed x->[ -2.64468904e+35  -3.62826687e+35  -5.43081399e+35  -5.59542252e+35\n",
      "  -5.76003105e+35]\n",
      "x->[ -2.64468904e+35  -3.62826687e+35  -5.43081399e+35  -5.59542252e+35\n",
      "  -5.76003105e+35]\n",
      "f(x)->-9.169104647989091e+73\n",
      "gradient->[  4.24909947e+37   5.82936845e+37   8.72543749e+37   8.98990639e+37\n",
      "   9.25437530e+37]\n",
      "recomputed x->[  3.98463057e+36   5.46654176e+36   8.18235609e+36   8.43036414e+36\n",
      "   8.67837219e+36]\n",
      "x->[  3.98463057e+36   5.46654176e+36   8.18235609e+36   8.43036414e+36\n",
      "   8.67837219e+36]\n",
      "f(x)->-2.0813917286540068e+76\n",
      "gradient->[ -6.40192152e+38  -8.78283964e+38  -1.31462128e+39  -1.35446759e+39\n",
      "  -1.39431389e+39]\n",
      "recomputed x->[ -6.00345846e+37  -8.23618547e+37  -1.23279772e+38  -1.27016395e+38\n",
      "  -1.30753017e+38]\n",
      "x->[ -6.00345846e+37  -8.23618547e+37  -1.23279772e+38  -1.27016395e+38\n",
      "  -1.30753017e+38]\n",
      "f(x)->-4.72477051405387e+78\n",
      "gradient->[  9.64547885e+39   1.32326980e+40   1.98067904e+40   2.04071363e+40\n",
      "   2.10074821e+40]\n",
      "recomputed x->[  9.04513301e+38   1.24090794e+39   1.85739927e+39   1.91369723e+39\n",
      "   1.96999520e+39]\n",
      "x->[  9.04513301e+38   1.24090794e+39   1.85739927e+39   1.91369723e+39\n",
      "   1.96999520e+39]\n",
      "f(x)->-1.0725254695284578e+81\n",
      "gradient->[ -1.45323966e+41  -1.99370936e+41  -2.98419744e+41  -3.07464877e+41\n",
      "  -3.16510010e+41]\n",
      "recomputed x->[ -1.36278833e+40  -1.86961857e+40  -2.79845752e+40  -2.88327905e+40\n",
      "  -2.96810058e+40]\n",
      "x->[ -1.36278833e+40  -1.86961857e+40  -2.79845752e+40  -2.88327905e+40\n",
      "  -2.96810058e+40]\n",
      "f(x)->-2.4346386334862815e+83\n",
      "gradient->[  2.18952893e+42   3.00382962e+42   4.49615217e+42   4.63243100e+42\n",
      "   4.76870984e+42]\n",
      "recomputed x->[  2.05325010e+41   2.81686777e+41   4.21630642e+41   4.34410310e+41\n",
      "   4.47189978e+41]\n",
      "x->[  2.05325010e+41   2.81686777e+41   4.21630642e+41   4.34410310e+41\n",
      "   4.47189978e+41]\n",
      "f(x)->-5.5266429041260845e+85\n",
      "gradient->[ -3.29886190e+43  -4.52573107e+43  -6.77414438e+43  -6.97946939e+43\n",
      "  -7.18479440e+43]\n",
      "recomputed x->[ -3.09353689e+42  -4.24404429e+42  -6.35251374e+42  -6.54505908e+42\n",
      "  -6.73760443e+42]\n",
      "x->[ -3.09353689e+42  -4.24404429e+42  -6.35251374e+42  -6.54505908e+42\n",
      "  -6.73760443e+42]\n",
      "f(x)->-1.25455093703126e+88\n",
      "gradient->[  4.97024255e+44   6.81870954e+44   1.02062898e+45   1.05156435e+45\n",
      "   1.08249972e+45]\n",
      "recomputed x->[  4.66088886e+43   6.39430511e+43   9.57103844e+43   9.86113760e+43\n",
      "   1.01512368e+44]\n",
      "x->[  4.66088886e+43   6.39430511e+43   9.57103844e+43   9.86113760e+43\n",
      "   1.01512368e+44]\n",
      "f(x)->-2.8478374320710496e+90\n",
      "gradient->[ -7.48843442e+45  -1.02734341e+46  -1.53773445e+46  -1.58434334e+46\n",
      "  -1.63095223e+46]\n",
      "recomputed x->[ -7.02234553e+44  -9.63400356e+44  -1.44202407e+45  -1.48573196e+45\n",
      "  -1.52943986e+45]\n",
      "x->[ -7.02234553e+44  -9.63400356e+44  -1.44202407e+45  -1.48573196e+45\n",
      "  -1.52943986e+45]\n",
      "f(x)->-6.464606418211099e+92\n",
      "gradient->[  1.12824776e+47   1.54785076e+47   2.31683332e+47   2.38705678e+47\n",
      "   2.45728024e+47]\n",
      "recomputed x->[  1.05802430e+46   1.45151073e+46   2.17263092e+46   2.23848358e+46\n",
      "   2.30433625e+46]\n",
      "x->[  1.05802430e+46   1.45151073e+46   2.17263092e+46   2.23848358e+46\n",
      "   2.30433625e+46]\n",
      "f(x)->-1.4674691635043266e+95\n",
      "gradient->[ -1.69987867e+48  -2.33207511e+48  -3.49066554e+48  -3.59646797e+48\n",
      "  -3.70227040e+48]\n",
      "recomputed x->[ -1.59407624e+47  -2.18692403e+47  -3.27340245e+47  -3.37261961e+47\n",
      "  -3.47183678e+47]\n",
      "x->[ -1.59407624e+47  -2.18692403e+47  -3.27340245e+47  -3.37261961e+47\n",
      "  -3.47183678e+47]\n",
      "f(x)->-3.331162961088667e+97\n",
      "gradient->[  2.56112852e+49   3.51362963e+49   5.25922421e+49   5.41863184e+49\n",
      "   5.57803946e+49]\n",
      "recomputed x->[  2.40172090e+48   3.29493723e+48   4.93188397e+48   5.08136988e+48\n",
      "   5.23085579e+48]\n",
      "x->[  2.40172090e+48   3.29493723e+48   4.93188397e+48   5.08136988e+48\n",
      "   5.23085579e+48]\n",
      "f(x)->-7.56175799076428e+99\n",
      "gradient->[ -3.85873381e+50  -5.29382314e+50  -7.92382971e+50  -8.16400180e+50\n",
      "  -8.40417389e+50]\n",
      "recomputed x->[ -3.61856172e+49  -4.96432942e+49  -7.43064132e+49  -7.65586482e+49\n",
      "  -7.88108832e+49]\n",
      "x->[ -3.61856172e+49  -4.96432942e+49  -7.43064132e+49  -7.65586482e+49\n",
      "  -7.88108832e+49]\n",
      "f(x)->-1.7165231655974052e+102\n",
      "gradient->[  5.81377564e+51   7.97595832e+51   1.19384675e+52   1.23003237e+52\n",
      "   1.26621798e+52]\n",
      "recomputed x->[  5.45191947e+50   7.47952538e+50   1.11954034e+51   1.15347372e+51\n",
      "   1.18740710e+51]\n",
      "x->[  5.45191947e+50   7.47952538e+50   1.11954034e+51   1.15347372e+51\n",
      "   1.18740710e+51]\n",
      "f(x)->-3.896516896773543e+104\n",
      "gradient->[ -8.75934668e+52  -1.20170072e+53  -1.79871364e+53  -1.85323284e+53\n",
      "  -1.90775203e+53]\n",
      "recomputed x->[ -8.21415474e+51  -1.12690547e+52  -1.68675961e+52  -1.73788547e+52\n",
      "  -1.78901132e+52]\n",
      "x->[ -8.21415474e+51  -1.12690547e+52  -1.68675961e+52  -1.73788547e+52\n",
      "  -1.78901132e+52]\n",
      "f(x)->-8.845114491395516e+106\n",
      "gradient->[  1.31973022e+54   1.81054686e+54   2.71003860e+54   2.79218014e+54\n",
      "   2.87432169e+54]\n",
      "recomputed x->[  1.23758868e+53   1.69785632e+53   2.54136264e+53   2.61839160e+53\n",
      "   2.69542056e+53]\n",
      "x->[  1.23758868e+53   1.69785632e+53   2.54136264e+53   2.61839160e+53\n",
      "   2.69542056e+53]\n",
      "f(x)->-2.007845787366591e+109\n",
      "gradient->[ -1.98837645e+55  -2.72786716e+55  -4.08308973e+55  -4.20684859e+55\n",
      "  -4.33060746e+55]\n",
      "recomputed x->[ -1.86461758e+54  -2.55808153e+54  -3.82895346e+54  -3.94500943e+54\n",
      "  -4.06106541e+54]\n",
      "x->[ -1.86461758e+54  -2.55808153e+54  -3.82895346e+54  -3.94500943e+54\n",
      "  -4.06106541e+54]\n",
      "f(x)->-4.5578208283991493e+111\n",
      "gradient->[  2.99579477e+56   4.10995120e+56   6.15180232e+56   6.33826407e+56\n",
      "   6.52472583e+56]\n",
      "recomputed x->[  2.80933301e+55   3.85414305e+55   5.76890697e+55   5.94376313e+55\n",
      "   6.11861929e+55]\n",
      "x->[  2.80933301e+55   3.85414305e+55   5.76890697e+55   5.94376313e+55\n",
      "   6.11861929e+55]\n",
      "f(x)->-1.0346278003269913e+114\n",
      "gradient->[ -4.51362532e+57  -6.19227326e+57  -9.26863583e+57  -9.54956913e+57\n",
      "  -9.83050243e+57]\n",
      "recomputed x->[ -4.23269202e+56  -5.80685895e+56  -8.69174513e+56  -8.95519282e+56\n",
      "  -9.21864050e+56]\n",
      "x->[ -4.23269202e+56  -5.80685895e+56  -8.69174513e+56  -8.95519282e+56\n",
      "  -9.21864050e+56]\n",
      "f(x)->-2.3486107188321523e+116\n",
      "gradient->[  6.80047037e+58   9.32961152e+58   1.39646246e+59   1.43878938e+59\n",
      "   1.48111630e+59]\n",
      "recomputed x->[  6.37720117e+57   8.74892563e+57   1.30954501e+58   1.34923745e+58\n",
      "   1.38892990e+58]\n",
      "x->[  6.37720117e+57   8.74892563e+57   1.30954501e+58   1.34923745e+58\n",
      "   1.38892990e+58]\n",
      "f(x)->-5.331359071223459e+118\n",
      "gradient->[ -1.02459540e+60  -1.40564939e+60  -2.10398536e+60  -2.16775737e+60\n",
      "  -2.23152938e+60]\n",
      "recomputed x->[ -9.60823385e+58  -1.31816013e+59  -1.97303086e+59  -2.03283363e+59\n",
      "  -2.09263639e+59]\n",
      "x->[ -9.60823385e+58  -1.31816013e+59  -1.97303086e+59  -2.03283363e+59\n",
      "  -2.09263639e+59]\n",
      "f(x)->-1.2102214010353408e+121\n",
      "gradient->[  1.54371046e+61   2.11782688e+61   3.16997736e+61   3.26605970e+61\n",
      "   3.36214204e+61]\n",
      "recomputed x->[  1.44762812e+60   1.98601086e+60   2.97267428e+60   3.06277634e+60\n",
      "   3.15287840e+60]\n"
     ]
    }
   ],
   "source": [
    "#9\n",
    "\n",
    "x0 = np.array([10,20,30,40,50])\n",
    "a = np.array([[11,4,7,10,13],[4,17,10,13,16],[7,10,23,16,29],[10,13,16,29,22],[13,16,19,22,25]])\n",
    "\n",
    "\n",
    "def f(a,x):\n",
    "    return -1*np.matmul(np.transpose(x),np.matmul(a,x))\n",
    "\n",
    "def gradient(a,x):\n",
    "    return -2*(np.matmul(a,x))\n",
    "\n",
    "#iterative gradient ascent function\n",
    "def gradientAscent2D(x0, r, iterations, e):\n",
    "    x=x0\n",
    "    iterCount=1\n",
    "    while(iterCount<=iterations):\n",
    "        print(\"x->{0}\".format(x))\n",
    "        print(\"f(x)->{0}\".format(f(a,x)))\n",
    "        print(\"gradient->{0}\".format(gradient(a,x)))\n",
    "        x = x + r * gradient(a,x)\n",
    "        print(\"recomputed x->{0}\".format(x))\n",
    "        '''\n",
    "        if(abs(gradient(a,x))<e):\n",
    "            print(\"maxima reached in {0} iterations!\".format(iterCount))\n",
    "            break\n",
    "        '''\n",
    "        iterCount+=1\n",
    "\n",
    "#print(f(a,x0))\n",
    "#print(gradient(a,x0))\n",
    "\n",
    "gradientAscent2D(x0, 0.1, 50, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample size-->10\n",
      "mean-->0.0141487037234\n",
      "standard deviation-->0.328167389307\n",
      "95% confidence interval-->(-0.0062258102629996846, 0.034523217709785003)\n",
      "-----------------------------------\n",
      "sample size-->1000\n",
      "mean-->0.00183356847885\n",
      "standard deviation-->0.0322041285783\n",
      "95% confidence interval-->(-0.00016584855501089717, 0.0038329855127062738)\n",
      "-----------------------------------\n",
      "sample size-->100000\n",
      "mean-->-4.78945872231e-05\n",
      "standard deviation-->0.00316104167354\n",
      "95% confidence interval-->(-0.00024415018691877912, 0.00014836101247258439)\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "#PART 2\n",
    "#1,2,3,4\n",
    "\n",
    "def normalProperties(n):\n",
    "    mu = 0\n",
    "    sigma = 1\n",
    "    means = []\n",
    "    for repetition in range(1000):\n",
    "        ndist = np.random.normal(mu, sigma, n)\n",
    "        means.append(np.mean(ndist))\n",
    "    print(\"sample size-->\"+str(n))\n",
    "    print(\"mean-->\"+str(np.mean(means)))\n",
    "    print(\"standard deviation-->\"+str(np.std(means)))\n",
    "    #using interval function from scipy.stats instead of quantiles\n",
    "    print(\"95% confidence interval-->\"+str(st.t.interval(0.95, len(means)-1, loc=np.mean(means), scale=st.sem(means))))\n",
    "    print(\"-----------------------------------\")\n",
    "\n",
    "for i in [10, 1000, 100000]:\n",
    "    normalProperties(i)\n",
    "    \n",
    "#as the values below indicate, the mean, and standard deviations decrease and the 95% CI tightens as our sample size increases\n",
    "#that is, our samples' properties become closer to an actual normal distribution with an increase in sample size\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xe5fa910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#5\n",
    "a, m = 3., 2.  # shape and mode\n",
    "s = (np.random.pareto(a, 1000) + 1) * m\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "count, bins, _ = plt.hist(s, 100, normed=True)\n",
    "fit = a*m**a / bins**(a+1)\n",
    "plt.plot(bins, max(count)*fit/max(fit), linewidth=2, color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample size-->10\n",
      "mean-->4.58808508927\n",
      "standard deviation-->18.9121313182\n",
      "95% confidence interval-->(3.4139114918605724, 5.7622586866783561)\n",
      "-----------------------------------\n",
      "sample size-->1000\n",
      "mean-->27.9200402103\n",
      "standard deviation-->573.77578781\n",
      "95% confidence interval-->(-7.7032520322520597, 63.543332452893942)\n",
      "-----------------------------------\n",
      "sample size-->100000\n",
      "mean-->18.9124402886\n",
      "standard deviation-->298.646545127\n",
      "95% confidence interval-->(0.37074964858462067, 37.454130928629489)\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "#6,7,8,9,10\n",
    "\n",
    "def paretoProperties(n):\n",
    "    mu = 0\n",
    "    sigma = 1\n",
    "    means = []\n",
    "    for repetition in range(1000):\n",
    "        a, m = 1, 0.5  # shape and mode\n",
    "        pdist = (np.random.pareto(a, n) + 1) * m\n",
    "        means.append(np.mean(pdist))\n",
    "    print(\"sample size-->\"+str(n))\n",
    "    print(\"mean-->\"+str(np.mean(means)))\n",
    "    print(\"standard deviation-->\"+str(np.std(means)))\n",
    "    #using interval function from scipy.stats instead of quantiles\n",
    "    print(\"95% confidence interval-->\"+str(st.t.interval(0.95, len(means)-1, loc=np.mean(means), scale=st.sem(means))))\n",
    "    print(\"-----------------------------------\")\n",
    "\n",
    "for i in [10, 1000, 100000]:\n",
    "    paretoProperties(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
